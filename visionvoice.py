# -*- coding: utf-8 -*-
"""VisionVoice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DCGzEIpYUP33Tdhlkz4pultTzkqRSkxn
"""

!pip install gradio langchain langchain-community transformers torch bitsandbytes pyht requests sentencepiece

import os
import torch
import requests
import random
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline
from langchain import HuggingFacePipeline, LLMChain
from langchain.prompts import PromptTemplate
from pyht import Client
from pyht.client import TTSOptions
from PIL import Image
from io import BytesIO
import gradio as gr

access_token = "YOUR-ACCESS-TOKEN"
model_name = "mistralai/Mistral-7B-Instruct-v0.1"

# Configure Bits and Bytes for 4-bit quantization
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
)

# Load the tokenizer and model for text generation
tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    token=access_token,
    quantization_config=bnb_config,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True,
)

# Set up the text generation pipeline
pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    torch_dtype=torch.bfloat16,
    max_new_tokens=500,
    pad_token_id=tokenizer.eos_token_id,
    device_map="auto",
    temperature=1.0,
    top_k=50,
    top_p=0.9
)
llm = HuggingFacePipeline(pipeline=pipe)

# Function to generate text from an image
def generate_text_from_image(url: str) -> str:
    device = 0 if torch.cuda.is_available() else -1
    image_to_text = pipeline("image-t1o-text", model="Salesforce/blip-image-captioning-base", device=device)

    generated_text = image_to_text(url)[0]["generated_text"]
    return generated_text

# Function to generate a complete children's story
def generate_story(image_url: str, user_input: str = "") -> str:
    image_text = generate_text_from_image(image_url)
    random_twist = random.choice([
        "a hidden treasure is discovered in the forest",
        "a magical bird helps the characters solve a riddle",
        "a secret door leads to a wonderful land of sweets",
        "a wise owl teaches them the value of friendship",
        "a sparkling rainbow lights up the sky and grants a wish",
    ])

    if user_input:
        template = """
        You are a creative storyteller specializing in engaging children's stories. Generate a complete story with the following requirements:
        - The story must have a clear beginning, middle, and end.
        - The characters should face an exciting challenge or adventure.
        - The ending must resolve all conflicts and leave the reader with a happy or thoughtful conclusion.

        CONTEXT: {scenario}
        USER INPUT: {user_input}
        RANDOM TWIST: {random_twist}

        Create the story below:
        BEGINNING:
        Start by introducing the characters and setting.

        MIDDLE:
        Describe their adventure or problem they encounter.

        END:
        Conclude with how the problem is resolved or how the adventure ends positively.

        STORY:
        """
        input_variables = ['scenario', 'user_input', 'random_twist']
        prompt = PromptTemplate(template=template, input_variables=input_variables)
        story = LLMChain(llm=llm, prompt=prompt, verbose=True)({"scenario": image_text, "user_input": user_input, "random_twist": random_twist})['text']
    else:
        template = """
        You are a creative storyteller specializing in engaging children's stories. Generate a complete story with the following requirements:
        - The story must have a clear beginning, middle, and end.
        - The characters should face an exciting challenge or adventure.
        - The ending must resolve all conflicts and leave the reader with a happy or thoughtful conclusion.

        CONTEXT: {scenario}
        RANDOM TWIST: {random_twist}

        Create the story below:
        BEGINNING:
        Start by introducing the characters and setting.

        MIDDLE:
        Describe their adventure or problem they encounter.

        END:
        Conclude with how the problem is resolved or how the adventure ends positively.

        STORY:
        """
        input_variables = ['scenario', 'random_twist']
        prompt = PromptTemplate(template=template, input_variables=input_variables)
        story = LLMChain(llm=llm, prompt=prompt, verbose=True)({"scenario": image_text, "random_twist": random_twist})['text']

    return story.split('STORY:')[-1].strip()


# Set up the TTS client
client = Client(
    user_id="YOUR-USER-ID",
    api_key="YOUR-API-KEY"
)
tts_options = TTSOptions(voice="s3://voice-cloning-zero-shot/d9ff78ba-d016-47f6-b0ef-dd630f59414e/female-cs/manifest.json")

# Function to generate and save speech from story
def generate_speech_from_story(story: str) -> str:
    audio_path = "story_audio.mp3"
    with open(audio_path, "wb") as f:
        for chunk in client.tts(story, tts_options):
            f.write(chunk)
    return audio_path

# Define Gradio UI
def process_story(image_url, user_input):
    story = generate_story(image_url, user_input)
    audio_file = generate_speech_from_story(story)
    return story, audio_file

import gradio as gr

theme = gr.themes.Soft()

with gr.Blocks(theme=theme) as demo:
    gr.Markdown("# VisionVoice ðŸŽ¨ðŸ“œ")
    gr.Markdown("Generate a creative story and audio narration from an image URL!")

    with gr.Row():
        image_url = gr.Textbox(label="Image URL", placeholder="Enter image URL...")
        user_input = gr.Textbox(label="User Input (Optional)", placeholder="Enter a custom prompt for the story...")

    with gr.Row():
        story_output = gr.Textbox(label="Generated Story", lines=10, interactive=False)
        audio_output = gr.Audio(label="Generated Audio", type="filepath")

    generate_button = gr.Button("Generate Story")
    generate_button.click(process_story, inputs=[image_url, user_input], outputs=[story_output, audio_output])

# Launch the app
demo.launch(debug=True)

